- Virtual Machine -> Debian
- Connect Virtual Machine and VS code
- root: makefile srcs obj
- Makefile:  build the Docker images using `docker-compose.yml`
- docker compose
- Docker image
- write your own Dockerfiles, one per service
- build yourself the Docker images of your project
- You then have to set up:
• A Docker container that contains NGINX with TLSv1.2 or TLSv1.3 only.
• A Docker container that contains WordPress + php-fpm (it must be installed and configured) only without nginx.
• A Docker container that contains MariaDB only without nginx.
• A volume that contains your WordPress database.
• A second volume that contains your WordPress website files.
• A docker-network that establishes the connection between your containers.
Your containers have to restart in case of a crash.
- Read about how daemons work and whether it’s a good idea to use them or not.
- PID 1 and the best practices for writing Dockerfiles.
- In your WordPress database, there must be two users, one of them being the administrator (Ying Yang)
- Your volumes will be available in the /home/login/data folder of the host machine using Docker. Of course, you have to replace the login with yours.
- configure your domain name so it points to your local IP address.
- This domain name must be login.42.fr. Example:  wil.42.fr will redirect to the IP address pointing to wil’s website.
- expected directory structure:
- ROOT: Makefile, srcs, secrets
- ./secrets: credentials.txt, db_password.txt, db_root_password.txt
- ./srcs: docker-compose.yml, .env, requirements
- ./srcs/requirements: bonus, mariadb, nginx, tools, wordpress
- . /srcs/requirements/mariadb: conf, Dockerfile, .dockerignore, tools
- ./srcs/requirements/nginx: conf, Dockerfile, .dockerignore, tools
- $> cat srcs/.env
	DOMAIN_NAME=wil.42.fr
	# MYSQL SETUP
	MYSQL_USER=XXXXXXXXXXXX
	[...]
-
-
- Step by step:
1) Read about (make sure you understand):
    - What is Docker?
    - What is Docker Compose?
    - What are Multi-container Applications?
    - What is a Docker Image?
    - What Are Volumes?
    - How Daemons Work?
2) Set up your Virtual Machine
    - Either with Alpine or Debian
3) Connect your Virtual Machine and VS code
    - Easier to use
4) You then have to set up:
    Your containers have to restart in case of a crash.
    • A Docker container that contains NGINX with TLSv1.2 or TLSv1.3 only.
    • A Docker container that contains WordPress + php-fpm (it must be installed and configured) only without nginx.
    • A Docker container that contains MariaDB only without nginx.
    • A volume that contains your WordPress database.
    • A second volume that contains your WordPress website files.
    • A docker-network that establishes the connection between your containers.
-
-
-------------------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------------------

Inception
This project is designed to broaden your understanding of system administration by using Docker.
You will virtualize several Docker images, creating them in your new personal virtual
machine.


1. What is Docker?
Docker is a platform that helps developers easily create, deploy, and run applications in containers. Containers are lightweight, portable environments that package everything needed to run a piece of software—code, libraries, dependencies, and configuration—so it can run reliably on any system, regardless of the environment.

Here’s a simple breakdown:
Key Concepts in Docker:
- 1) Containers:
    - A container is like a small, lightweight virtual machine that runs an application and its dependencies.
    - It ensures that the application works the same in different environments (e.g., on your laptop, in the cloud, or on a server).
    - Unlike full virtual machines, containers share the host system’s OS kernel, making them faster and more efficient in terms of resource usage.
- 2) Images:
    - A Docker image is like a template or blueprint for creating containers. It contains everything needed to run an app, including the code, libraries, environment variables, and system tools.
    - Images are read-only, and when a container starts from an image, it adds a writable layer on top of the image where it can make changes.
- 3) Docker Daemon:
    - The Docker daemon (dockerd) is the background service that runs on your host machine and is responsible for managing Docker containers, images, volumes, and networks.
    - It listens for Docker commands and executes them (like pulling images, starting containers, or creating networks).
- 4) Dockerfile:
    - A Dockerfile is a text file that contains a set of instructions to create a Docker image.
    - Think of it as a recipe: it specifies the base image (e.g., python:3.9), the app’s code, dependencies, and how to run the app.

Example of a simple Dockerfile:
```dockerfile
# Use an official Python runtime as the base image
FROM python:3.9

# Set the working directory in the container
WORKDIR /app

# Copy the current directory contents into the container at /app
COPY . /app

# Install the dependencies
RUN pip install -r requirements.txt

# Command to run the app
CMD ["python", "app.py"]
```
- 5) Docker Hub:
    - Docker Hub is like GitHub for Docker images. It’s a public registry where you can find and share Docker images.
    - You can pull official images (like nginx, mysql, or python) or push your own custom images to Docker Hub.

Why Use Docker?
- 1) Portability:
    - Docker ensures that your app will run the same way on different machines or environments. Once it's packed in a container, you can move that container across systems (from your laptop to production servers) without worrying about compatibility issues.
- 2) Consistency:
    - Since all dependencies and environment configurations are included inside the container, there are no "it works on my machine" problems anymore. Containers behave the same no matter where they run.
- 3) Lightweight:
    - Containers use less overhead compared to virtual machines because they share the host system's kernel, making them faster to start and requiring fewer resources.
- 4) Isolation:
    - Containers are isolated from one another and the host system. This isolation helps to avoid conflicts (e.g., two applications needing different versions of the same dependency).
- 5) Scalability:
    - Docker makes it easy to scale applications by running multiple instances of containers. This is especially useful in cloud environments where you can spin up containers as needed.

---

2. What is Docker Compose?
Docker Compose is a tool used to easily manage and run multi-container Docker applications.
- Imagine you have a project with multiple parts, like a web app, a database, and maybe a message broker. Instead of running each part manually, Docker Compose lets you define all of them in a single file (called docker-compose.yml) and start everything with one command.
So, Docker Compose simplifies running complex applications with multiple containers.

---

3. What are Multi-container Applications?
A multi-container application is an app that needs more than one Docker container to work.
- For example, let's say you have an e-commerce website. It might need:
    - A web server (like Nginx or Apache) to serve the website.
    - A database (like MySQL or MongoDB) to store user data.
    - A caching service (like Redis) to make things faster.
Each of these components runs in its own container, but they work together to make the entire app function. This setup is called a multi-container application.

---

4. What is a Docker Image?
A Docker image is like a blueprint or template for creating a Docker container.
- It contains everything needed to run an application, such as the code, libraries, and dependencies.
- When you start a container, it's created from a Docker image. The image is read-only and acts as a recipe for how the container should be built.
Think of a Docker image like a snapshot of your app environment that can be used to create multiple identical containers whenever you need.

---

5. What Are Volumes?
Docker volumes are used to persist data generated or used by Docker containers. Normally, when a container is stopped or removed, all the data inside it is lost. Volumes allow you to keep that data even after the container is deleted.

Here’s how volumes work:
- Volumes are stored on the host machine outside the container’s filesystem, usually in /var/lib/docker/volumes/.
- They allow data sharing between the host system and one or more containers.
- Volumes are independent of the container lifecycle, so data is safe even when the container is deleted or stopped.

Example Use Case:
Let’s say you’re running a database container like PostgreSQL. You don’t want to lose your data every time the container stops. By using a volume, you can store the database data on your host machine, so that if you recreate the container, your data will still be there.

How Volumes Are Defined in `docker-compose.yml`:
In the `docker-compose.yml` example I gave earlier, this section:
```yaml
volumes:
  db_data:
```
Defines a named volume called db_data. It is used by the PostgreSQL service to store its data:
```yaml
volumes:
  - db_data:/var/lib/postgresql/data
```
This means the database data is stored outside the container, and will be preserved even if the container is destroyed.

---

6. How Daemons Work?
A daemon is a background process that runs without user interaction. In Docker, the Docker daemon is the main program that manages containers, images, networks, and volumes. It listens for commands (like docker run or docker-compose up) and handles tasks like building, running, or stopping containers.

Here’s how Docker daemons work:
- `Docker Daemon (dockerd)` : The Docker daemon runs as a background process on the host machine. It listens to Docker API requests (commands you give Docker) and manages containers and resources (e.g., networks, volumes).
- `Client interaction` : The Docker client (CLI) is what you interact with when you run Docker commands. It communicates with the Docker daemon, which actually performs the tasks.
- `Container management` : The daemon handles everything related to containers, including creating, running, stopping, or destroying them.

Example:
When you run docker run to start a container, the Docker daemon:
- Pulls the required image if it’s not available locally.
- Creates a container from the image.
- Allocates resources (CPU, memory, storage) to the container.
- Runs the container in the background or attached to your terminal.

Should You Use Daemons?
The term daemon in Docker specifically refers to the background Docker process (the dockerd process), but in general computing, daemons refer to any background service or process. Let's look at when using daemons (background processes) is a good idea and when it might not be:

Advantages of Using Daemons (Background Processes):
- Automatic Management: Daemons can run automatically without user intervention. This is useful for services that need to be running at all times, like web servers, database servers, or background workers.
- Resource Management: Since they run in the background, you can better manage resources (CPU, memory) and keep your terminal free for other tasks.
- Continuous Service Availability: Daemons are perfect for tasks that need to be always on (like Docker itself, which runs the Docker daemon in the background to manage containers).

Disadvantages (or Why Not to Use Daemons):
- Difficult to Debug: If a daemonized process crashes or stops working correctly, it might be harder to troubleshoot since it runs in the background.
- Harder to Monitor: You may not realize if a daemon is misbehaving or consuming too many resources since it's not visible in the foreground.
- Overhead for Simple Tasks: For lightweight tasks that don't need to always be running (like one-time scripts or short-term jobs), using a daemon might add unnecessary complexity.

When to Use Them:
- Good Idea: Use daemons when you need to keep a service running continuously (e.g., a web server, a message broker, or a database service).
- Not a Good Idea: Avoid daemons for quick, one-off jobs or scripts that don't need to stay alive after they finish running.
In Docker's case, the daemon is essential for the system to function. Without it, you wouldn't be able to run containers, manage images, or interact with any of Docker’s features. For other software, whether or not you should use a daemon depends on the use case.

---

7. Extra: (Virtual Machine vs Docker)

Summary of Differences:

| Feature          | Virtual Machine (VM)                           | Docker (Container)                               |
| ---------------- | ---------------------------------------------- | ------------------------------------------------ |
| **Architecture**  | Full guest OS on top of host OS                | Shares host OS kernel, isolated by processes      |
| **Startup Speed** | Slow (minutes)                                 | Fast (seconds)                                   |
| **Resource Usage**| Heavy, each VM needs its own OS                | Lightweight, shares host OS                      |
| **Isolation**     | Full OS isolation (secure, but heavier)        | Process-level isolation, lighter but less isolated|
| **Portability**   | Less portable, larger images (full OS)         | Highly portable, smaller images                  |
| **Performance**   | Slower (due to full OS overhead)               | Faster (less overhead)                           |
| **Use Cases**     | Running multiple OSes, legacy apps, full OS isolation | Microservices, cloud apps, lightweight tasks  |
| **Size of Images**| Large (GBs)                                    | Small (MBs to GBs)                               |

In Summary:
- `Docker (containers)` is more lightweight, faster, and more efficient when running multiple applications on the same machine. It's great for modern app development, where speed, portability, and scalability are key.
- `Virtual machines (VM)` offer more complete isolation and are better suited when you need to run different operating systems or when full OS separation is required.

---

# .env
General
DOMAIN_NAME=jmetzger.42.fr:
This specifies the domain name for the WordPress site. In this case, it seems to be a subdomain (jmetzger) of 42.fr, possibly referring to a user or server identifier.

MYSQL_HOST=mariadb:
This is the hostname or IP address of the database server (MariaDB in this case). The value mariadb indicates that it expects the database service to be running on the same server or a server accessible by that name (e.g., within a Docker container network).

MYSQL_DATABASE=wordpress:
This sets the name of the MySQL database that will be used for WordPress. The database is named wordpress.

MYSQL_ROOT_PASSWORD=root:
The password for the MySQL root user (the administrative user). Here, it’s set to root (which is a poor security practice, but it might be placeholder text for setup purposes).

Database Administrator
MYSQL_USER=bob:
This creates a MySQL user named bob, which will be the non-root user for interacting with the WordPress database.

MYSQL_PASSWORD=bob:
The password for the bob MySQL user is set to bob.

WordPress Admin (WordPress Backend)
WP_ADMIN=wordpress:
This sets the WordPress admin username to wordpress, which is used to log in to the WordPress dashboard.

WP_ADMIN_PWD=wordpress:
This sets the WordPress admin password to wordpress.

WP_ADMIN_EMAIL=wordpress@gmail.com:
This specifies the email address associated with the WordPress admin account. Here, it's set to wordpress@gmail.com, but this would typically be changed to a real email address during setup.

WordPress User (Frontend User Account)
WP_USR=wp_user:
This is the name of a regular user for the WordPress site, named wp_user. This could be a default user account created during setup.

WP_USER_PWD=wp_user:
The password for the wp_user is set to wp_user.

WP_USRR_EMAIL=user_wordpress@gmail.com:
The email address associated with the regular wp_user account is user_wordpress@gmail.com.

Summary
This configuration defines several key settings for deploying a WordPress instance:

Database connection details (hostname, database name, credentials)
WordPress admin credentials (for managing the site)
A regular user account (presumably for testing the site as a normal user)
Keep in mind, the actual passwords (root, bob, wordpress, etc.) should be changed to something more secure in a real deployment. The file likely serves as part of an environment setup for a WordPress installation, where these variables are injected into scripts or Docker containers to automate the deployment.

---

# makefile
```
all:
	@docker-compose -f $(COMPOSE_FILE) up -d --build
```
Purpose: The all target builds and starts the Docker containers.
- `up:` This command starts (or creates, if not already created) the Docker services defined in the docker-compose.yml file.
- `-d:` Runs the containers in detached mode, which means the containers will run in the background, and the terminal won't be blocked.
- `--build:` This flag forces the rebuilding of images before starting the services. If there are changes in your Dockerfile or project, they will be included.

```
down:
	@docker-compose -f $(COMPOSE_FILE) down
```
Purpose: The down target stops and removes the running Docker containers, along with any associated networks and temporary resources.
- `down:` This stops the containers and removes all related resources, including networks, volumes (unless explicitly persisted), and containers defined by the docker-compose.yml file.

```
clean: down
	docker system prune -af
	docker volume prune -f
```
Purpose: The clean target stops and removes all Docker containers and associated resources, and then aggressively cleans up unused Docker resources (like unused images, stopped containers, and volumes).
- `docker system prune -af:` This command removes all unused Docker objects (such as dangling images, stopped containers, and unused networks). The -a flag ensures that all unused images (not just dangling ones) are removed, and the -f flag forces it without asking for confirmation.
- `docker volume prune -f:` This removes all unused Docker volumes. The -f flag forces it without a prompt.

Both makefiles work:
option1
```Makefile
# Paths
COMPOSE_FILE	=	./scrs/docker-compose.yml

# --- Targets ---
# Builds and starts the Docker services
all:
	@docker-compose -f $(COMPOSE_FILE) up -d --build

# Stops and removes the containers, networks, and any temporary resources created
down:
	@docker-compose -f $(COMPOSE_FILE) down

# Rebuild and restart of the services
re: down all

# Cleans up Docker resources
clean: down
	docker system prune -af
	docker volume prune -f

.PHONY: all down re clean
```

option2
```
# Executable
NAME 			= inception

# Paths
COMPOSE_FILE	=	./scrs/docker-compose.yml

# --- Targets ---
# Builds and starts the Docker services
all: $(NAME)

# Starts Docker services
$(NAME):
	@docker-compose -f $(COMPOSE_FILE) up -d --build

# Stops and removes the containers, networks, and any temporary resources created
down:
	@docker-compose -f $(COMPOSE_FILE) down

# Rebuild and restart of the services
re: down all

# Cleans up Docker resources
clean: down
	@docker system prune -af
	@docker volume prune -f

.PHONY: all down re clean
```

---
# docker-compse.yml

1. General Overview
This Docker Compose file defines a multi-container application that consists of three main services:

MariaDB: The database service.
Nginx: The web server that will serve the website.
WordPress: The WordPress application itself.
The volumes and networks help manage data persistence and network communication between these services.

2. Detailed Explanation of Volumes
Volumes and Their Purpose:
Why volumes?
Docker containers are designed to be ephemeral (short-lived), meaning that any data generated within the container during runtime will be lost once the container is stopped or removed. Volumes are used to persist important data outside of the container, ensuring that it survives container reboots or even complete removals.

Why use bind mounts?
Bind mounts allow you to map a specific directory on the host machine to a directory in the container. This is especially useful for persistent data storage, like the MySQL database and WordPress content (uploads, themes, plugins). In your case:

MariaDB: Needs to persist its database data.
WordPress: Needs to persist website content, like uploads, themes, and plugins.
Updated docker-compose.yml with Detailed Comments
```yaml
version: "3.8"

services:
  mariadb:
    build: 
      context: requirements/mariadb  # Builds the image from a Dockerfile located in "requirements/mariadb"
    args:
      MYSQL_DATABASE: ${MYSQL_DATABASE}      # Passes environment variables to the build process
      MYSQL_USER: $MYSQL_USER
      MYSQL_PASSWORD: $MYSQL_PASSWORD
      MYSQL_ROOT_PASSWORD: $MYSQL_ROOT_PASSWORD
    container_name: mariadb                  # Names the container "mariadb" for easier reference
    image: mariadb                           # Pulls the official MariaDB image
    restart: unless-stopped                  # Restarts the container automatically unless explicitly stopped
    env_file:
      - .env                                 # Loads environment variables from the ".env" file
    volumes:
      - mariadb:/var/lib/mysql               # Binds the host directory to the MySQL data directory inside the container.
                                             # This ensures the MySQL database persists across container restarts.
    networks:
      - inception                            # Connects to the "inception" network, allowing it to communicate with other services

  nginx:
    build: requirements/nginx                # Builds the image from a Dockerfile in "requirements/nginx"
    container_name: nginx                    # Names the container "nginx"
    image: nginx                             # Uses the official Nginx image
    depends_on:
      - wordpress                            # Ensures that the "wordpress" service is started before "nginx"
    restart: unless-stopped                  # Restarts the container unless explicitly stopped
    env_file:
      - .env                                 # Loads environment variables from the ".env" file
    ports:
      - "443:443"                            # Exposes port 443 for HTTPS traffic
    volumes:
      - nginx:/var/www/html                  # If you have any static content or configuration to persist for Nginx, 
                                             # you can map a directory here. Otherwise, it can be empty.
    networks:
      - inception                            # Connects to the "inception" network, allowing it to communicate with other services

  wordpress:
    build:
      context: requirements/wordpress        # Builds the image from a Dockerfile located in "requirements/wordpress"
    args:
      MYSQL_DATABASE: "${MYSQL_DATABASE}"    # Passes environment variables to the build process
      MYSQL_USER: "${MYSQL_USER}"
      MYSQL_PASSWORD: "${MYSQL_PASSWORD}"
      MYSQL_HOST: "${MYSQL_HOST}"
    container_name: wordpress                # Names the container "wordpress"
    image: wordpress                         # Uses the official WordPress image
    depends_on:
      - mariadb                              # Ensures that MariaDB is started before WordPress
    restart: unless-stopped                  # Restarts the container unless explicitly stopped
    env_file:
      - .env                                 # Loads environment variables from the ".env" file
    volumes:
      - wordpress:/var/www/html              # Binds the WordPress files directory from the host to the container.
                                             # This ensures that WordPress content (e.g., themes, uploads) persists.
    networks:
      - inception                            # Connects to the "inception" network, allowing it to communicate with other services

# Network configuration
networks:
  inception:
    name: inception                          # Defines a custom bridge network named "inception" to allow communication between containers.

# Volumes configuration to persist data
volumes:
  mariadb:
    name: mariadb                           # Defines the volume name as "mariadb"
    driver: local                           # Volume is located on the local host system
    driver_opts:
      type: none                            # No special filesystem type is enforced
      o: bind                               # Bind mounts the host directory to the container
      device: /home/jmetzger/data/mysql     # This is the host directory where MariaDB will persist its database files

  wordpress:
    name: wordpress                         # Defines the volume name as "wordpress"
    driver: local                           # Volume is located on the local host system
    driver_opts:
      type: none                            # No special filesystem type is enforced
      o: bind                               # Bind mounts the host directory to the container
      device: /home/jmetzger/data/html      # This is the host directory where WordPress files (themes, plugins, uploads) will be stored
```
3. Why Each Part is Necessary
MariaDB Volume (mariadb:/var/lib/mysql):

Reason: MariaDB stores the actual database files in /var/lib/mysql within the container. By binding this to a host directory, you ensure that your databases are persistent across container restarts. Without this, any database data would be lost when the container stops.
WordPress Volume (wordpress:/var/www/html):

Reason: WordPress stores files such as themes, plugins, and uploads in /var/www/html. By binding this directory to the host, your WordPress website's content persists even when the container is restarted or removed.
Nginx Volume (nginx:/var/www/html):

Optional Use Case: If you need to store static files, custom configurations, or logs, you can bind mount a directory for Nginx. Since you're using WordPress and Nginx is just serving it, this may not be necessary unless you're doing something like custom Nginx configurations.
Conclusion
Volumes ensure that critical data (like the MariaDB database and WordPress content) persists across container restarts.
Networks allow your containers to communicate with each other internally on a dedicated Docker network.
Service Definitions detail how each container should be built, managed, and restarted.
This setup provides a robust architecture for running a WordPress site backed by MariaDB with Nginx acting as a reverse proxy, ensuring data persistence and internal communication.






You said:
what are these?
version: "3.8"

services:
ChatGPT said:
ChatGPT
In a Docker Compose file, the version and services keys are essential components that define the structure of your multi-container Docker application. Here's a detailed explanation of what they are:

1. version
The version key specifies the version of the Compose file format you're using. This is important because different versions support different features. In your case, you've specified version: "3.8", which is part of the Docker Compose version 3 family.

Why version matters:
It determines what features and syntax are available in your Compose file.
Docker Compose version 3.x is widely used for modern applications, especially for deploying in production environments, and is compatible with Docker Swarm.
Version 3.8 specifically adds support for newer features and configurations, but still maintains backward compatibility with previous 3.x versions.
2. services
The services key defines all the individual services (containers) that make up your application. Each service runs in its own container and represents a specific part of your application.

Each service corresponds to a container.
In your example, under services, you define three services: mariadb, nginx, and wordpress. Each one represents a different container that is built and managed by Docker Compose.
Breakdown of services
mariadb:

This service defines a MariaDB container (the database).
It will be used to store and serve data for your WordPress application.
nginx:

This service defines an Nginx container (the web server).
Nginx acts as a reverse proxy that handles web traffic and directs it to the WordPress service.
wordpress:

This service defines a WordPress container (the application).
It will run the actual WordPress site, and it depends on the MariaDB database for data storage.
Example Structure:
```yaml
version: "3.8"           # Defines the version of the Docker Compose file format being used

services:                 # Defines the application services (containers) 
  mariadb:                # This is the MariaDB service (container)
    ...

  nginx:                  # This is the Nginx service (container)
    ...

  wordpress:              # This is the WordPress service (container)
    ...
```
Each of the services under services: will have its own specific configuration, such as:

Images (what Docker image to use)
Volumes (how to persist data)
Ports (what ports to expose)
Networks (how the service connects to other services)
In summary:

version: Specifies the Docker Compose file format.
services: Defines the different parts (containers) of your application that will work together to create a multi-container environment.
These two keys are critical in setting up a Docker Compose environment that ties together multiple containers into a functioning application.

1. What is the networks section?
The networks section in a Docker Compose file defines the networking configuration for your containers. Docker uses networks to allow containers to communicate with each other. Containers that are connected to the same network can talk to each other directly, using their container names as hostnames.

In Docker Compose, you can define custom networks so that specific services can communicate privately and securely.
By default, Docker Compose creates a network for you, but it's a good practice to define your own networks for better control, especially in more complex applications.
2. What is the inception network in your example?
The inception network is a custom network that you’ve defined in your Docker Compose file. All the services (containers) in your file — mariadb, nginx, and wordpress — are connected to this network, which allows them to communicate with each other.

yaml
Copy code
networks:              # Define custom networks for the services
  inception:           # Custom network named "inception"
    name: inception    # The actual network name is "inception"
inception: This is the name of the network within the Compose file. It's just an identifier.
name: inception: This specifies the actual name of the network that Docker will create. In this case, the name is "inception."
When Docker Compose runs, it creates this network and attaches the containers that use it to the network. This way, the mariadb, nginx, and wordpress containers can communicate because they are all attached to the same network.

3. Why do you need a custom network?
Internal Communication: All services in your Compose file (mariadb, nginx, and wordpress) are connected to the inception network. This allows the services to communicate internally using container names as hostnames (e.g., the WordPress service can talk to MariaDB by using mariadb as the hostname).

Isolation and Security: Custom networks ensure that services are isolated from other containers running outside of this Compose setup. Other Docker containers that are not on the inception network cannot communicate with the services defined here.

Easy Service Discovery: Docker automatically provides service discovery on custom networks. For example, in your WordPress container, if you set MYSQL_HOST: mariadb, Docker will know to resolve mariadb to the correct container's IP address because both services are on the same inception network.

4. How is it used in your services?
In each service (MariaDB, Nginx, WordPress), the networks section specifies that the container should be connected to the inception network:

yaml
Copy code
services:
  mariadb:
    ...
    networks:
      - inception        # Connect MariaDB to the "inception" network

  nginx:
    ...
    networks:
      - inception        # Connect Nginx to the "inception" network

  wordpress:
    ...
    networks:
      - inception        # Connect WordPress to the "inception" network
This ensures that:

MariaDB, WordPress, and Nginx can communicate with each other internally on the inception network.
The services are isolated from other Docker containers not connected to the same network.
5. When would you use multiple networks?
In more complex applications, you might want to define multiple networks to control how different services interact. For example:

Frontend and Backend Networks: You could have an internal network for sensitive services (like databases) and an external network for web-facing services. This would prevent unnecessary exposure of your database to the internet-facing containers.
In your case, using a single custom network, inception, simplifies communication between all services while keeping them isolated from other Docker containers running on your system.

Summary
networks: Defines the network(s) that services can use to communicate.
Custom Network (inception): Allows your services (MariaDB, Nginx, WordPress) to communicate privately and securely.
Service Discovery: Containers can reach each other by name (e.g., WordPress can reach MariaDB by using mariadb as the hostname).
Isolation: Services are isolated from other Docker containers not in the inception network.
By explicitly defining the inception network, you're ensuring all services can talk to each other while remaining secure and isolated from any other containers running outside of this application.




The args section in your Docker Compose file is important, but its significance depends on how you're building your Docker image. Here's a detailed explanation:

What are args in Docker Compose?
args are build-time variables used to pass values into the build process when Docker is constructing an image. They are defined in the Dockerfile and can be supplied during the docker build process.
They are different from environment variables (env or env_file), which are runtime variables that containers use while they are running. args only affect the image-building stage, not the actual running container.
Example in Your Case:
yaml
Copy code
args:
  MYSQL_DATABASE : ${MYSQL_DATABASE}
  MYSQL_USER : $MYSQL_USER
  MYSQL_PASSWORD : $MYSQL_PASSWORD
  MYSQL_ROOT_PASSWORD : $MYSQL_ROOT_PASSWORD
In this section, the args are passing the database details (like the database name, user, and password) to the build process when Docker creates the MariaDB image.
These values come from environment variables (typically defined in the .env file), and Docker substitutes them during the build phase.
Are args important?
Yes, if you're building custom images. If your Dockerfile is designed to use these args during the image build process, then they are necessary for the successful build of the image.

For example:

If your Dockerfile for MariaDB in requirements/mariadb uses these arguments (e.g., setting default environment variables or configuring certain behaviors in the image), then the args are essential for building the image with the correct database setup.

In a typical Dockerfile, you might see something like this:

Dockerfile
Copy code
ARG MYSQL_DATABASE
ARG MYSQL_USER
ARG MYSQL_PASSWORD
ARG MYSQL_ROOT_PASSWORD

# Use these ARG values to set up the MariaDB configuration at build-time.
If you're using a pre-built image (like the official mariadb image) and don't need to customize it at build time, the args section may not be necessary. Instead, you would only need to use environment variables (env_file or environment) to configure MariaDB at runtime.

If you’re using a pre-built MariaDB image
If you're simply using the official mariadb image and not customizing it with a custom Dockerfile in requirements/mariadb, the args section may be redundant. In that case, you can pass all configuration using the environment variables at runtime:

Using env_file: You already have this in your Compose file, where the environment variables are loaded from .env and passed to the container at runtime.
Should you keep args?
If you're building a custom MariaDB image from the requirements/mariadb directory (where you have a Dockerfile that uses these args), then you should keep them. They ensure the image is built with the correct settings.

If you're using a pre-built image (like image: mariadb from Docker Hub) and you're not building a custom image, you likely don't need the args section. You can rely solely on env_file or environment variables to pass configuration when the container starts.

To summarize:
args are important if you're building a custom Docker image from a Dockerfile and need to pass certain configuration options during the build process.
If you're using pre-built images, you probably don’t need args and can configure the container using environment variables (env_file).
Check if you have a Dockerfile in requirements/mariadb. If it uses ARG instructions, the args are necessary. If not, you might be able to remove them.





how do I know what a docker-compose.yml needs?
ChatGPT said:
ChatGPT
To understand what your docker-compose.yml file needs, you should focus on what your application requires to run properly within a Docker environment. This will depend on the architecture of your app, the services it needs, and how those services should interact. Here's a step-by-step guide to figuring out what your docker-compose.yml file needs:

1. Understand Your Application’s Components
The first step is to break down the components of your application. For example, in the case of a typical web application, you may need:

A web server (e.g., Nginx or Apache).
An application server (e.g., WordPress, Django, Node.js).
A database (e.g., MariaDB, PostgreSQL, MongoDB).
Other dependencies (e.g., Redis, a caching server, or message queues).
You need to determine which services your application requires. In your current example, the components are:

MariaDB: A database for storing data.
WordPress: The actual application (web-based content management system).
Nginx: A web server to handle traffic and serve the WordPress application.
2. Determine Container Requirements for Each Component
Once you know the services, determine what each container needs. Think about:

Docker images: Which Docker images should be used for each service? Should you use pre-built images (e.g., from Docker Hub) or build custom ones from a Dockerfile?

In your example, you use images like mariadb, nginx, and wordpress.
Volumes: Does the service need persistent storage? Some services, like databases, need volumes to store data so that it's not lost when the container restarts.

Example: MariaDB and WordPress need volumes to persist their data across container restarts.
Ports: What ports need to be exposed to access the services externally?

Example: Nginx may expose port 443 to serve your web application over HTTPS.
Environment Variables: Does the service need environment variables to be configured, like database credentials?

Example: MariaDB needs variables like MYSQL_USER, MYSQL_PASSWORD, and MYSQL_DATABASE to set up the database.
3. Services Section
For each component, you define a service. A service represents a container and its associated configuration.

Image: What Docker image will be used (e.g., mariadb, wordpress, or nginx)?
Build: If you need a custom image, you specify a build section that tells Docker Compose where to find the Dockerfile.
Environment Variables: What configuration does the container need at runtime? For instance, databases need credentials.
Volumes: Do you need to store data persistently or share files between the container and the host?
Ports: Which ports need to be mapped between the host and the container?
4. Networking Configuration
Think about how your containers should communicate with each other. You often need to create a custom network in Docker Compose to allow your services to interact securely.

Why? Containers on the same network can communicate using their service names as hostnames.
Example: Your nginx container might talk to wordpress, and WordPress might need to talk to the mariadb container for database access.
5. Volumes for Data Persistence
Some services, like databases and CMS platforms (e.g., WordPress), need to persist data. You should configure volumes to ensure data is not lost when containers are restarted or rebuilt.

Why? Without volumes, any data created inside a container will be lost when the container is stopped or destroyed.
Example: MariaDB needs a volume to persist its database files, and WordPress needs a volume to persist its content files.
6. Handling Dependencies Between Services
Some services depend on others. For example, WordPress needs the MariaDB service to be up before it can start.

Use depends_on: You can specify dependencies between services using the depends_on key in Docker Compose. This ensures services start in the correct order.
yaml
Copy code
depends_on:
  - mariadb    # Ensure MariaDB is started before WordPress
7. Use Environment Files for Configuration
To avoid hardcoding sensitive configuration values (like database passwords) directly in your docker-compose.yml, use an .env file.

Why? This keeps your Compose file clean and allows you to easily change configuration settings without editing the file itself.
Example: You can use .env to set variables like MYSQL_USER, MYSQL_PASSWORD, and MYSQL_DATABASE.
yaml
Copy code
env_file:
  - .env       # Load environment variables from an .env file
8. Restart Policies
You should define how Docker should handle container restarts. Use the restart policy to define whether containers should be automatically restarted if they crash.

yaml
Copy code
restart: unless-stopped    # Restart the container unless it is explicitly stopped
9. Special Features or Requirements
Lastly, consider if your application has any specific requirements, such as:

Ports: You may need to expose certain ports (e.g., 443 for HTTPS or 80 for HTTP).
Logging: You may want to configure logging or other monitoring tools.
Scaling: If you need multiple instances of a service, you can specify a number of replicas in Docker Compose.
Example: Building a Docker Compose File
Here’s how you’d build a docker-compose.yml file based on the requirements:

yaml
Copy code
version: "3.8"

services:
  mariadb:
    image: mariadb
    container_name: mariadb
    restart: unless-stopped
    env_file:
      - .env              # Load environment variables from .env file
    volumes:
      - mariadb:/var/lib/mysql  # Persist MariaDB data
    networks:
      - app_network        # Connect to the custom network

  wordpress:
    image: wordpress
    container_name: wordpress
    restart: unless-stopped
    depends_on:
      - mariadb            # Start MariaDB before WordPress
    env_file:
      - .env               # Load environment variables from .env file
    volumes:
      - wordpress:/var/www/html  # Persist WordPress content
    networks:
      - app_network        # Connect to the custom network

  nginx:
    image: nginx
    container_name: nginx
    restart: unless-stopped
    depends_on:
      - wordpress          # Start Nginx after WordPress
    ports:
      - "443:443"          # Expose port 443 (HTTPS)
    networks:
      - app_network        # Connect to the custom network

networks:
  app_network:
    name: inception        # Custom network for the app

volumes:
  mariadb:
    driver: local          # Local storage for MariaDB data
  wordpress:
    driver: local          # Local storage for WordPress content
Summary of What to Include:
Services:

Define all services (databases, web servers, etc.).
Use official or custom Docker images.
Set dependencies between services.
Build Requirements:

If building custom images, specify the build context.
Pass args if needed during the image build process.
Configuration:

Use environment variables or files (env_file).
Set up volumes for persistent storage.
Expose necessary ports for services.
Networking:

Define networks to allow inter-service communication.
Restart Policies:

Use appropriate restart policies for container health management.
By focusing on your application’s needs, you can tailor your docker-compose.yml file to ensure each service is properly configured, communicates securely, and can be easily managed.








---

# Dockerfile

The difference between a docker-compose.yml file and a Dockerfile lies in their purposes and roles within Docker-based development environments:

1. Dockerfile
A Dockerfile is a set of instructions used to build a Docker image. It defines everything needed to assemble the image, such as the base image, dependencies, configurations, and file structures. The image created from the Dockerfile can then be run as a container.

Key Points:
Purpose: To create a custom Docker image.
Usage: Defines how to build a single container image.
Syntax: Uses instructions like FROM, RUN, COPY, CMD, and others to describe what goes into the image.
Basic Example of a Dockerfile:
Dockerfile
Copy code
# Use an official Python runtime as a base image
FROM python:3.9

# Set the working directory in the container
WORKDIR /app

# Copy the current directory contents into the container at /app
COPY . /app

# Install any needed packages specified in requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

# Make port 80 available to the world outside this container
EXPOSE 80

# Define the command to run the app
CMD ["python", "app.py"]
What it does:
Pulls the Python 3.9 base image.
Copies local files into the container.
Installs Python dependencies.
Specifies the command to run the app.
2. docker-compose.yml
A docker-compose.yml file is used to define and run multi-container Docker applications. It allows you to manage multiple services, networks, and volumes in one place. While the Dockerfile defines how to build a single image, docker-compose.yml defines how to orchestrate multiple containers.

Key Points:
Purpose: To define and manage multi-container applications.
Usage: Specifies how to configure, connect, and manage multiple services, networks, and volumes.
Syntax: YAML-based configuration that specifies services, networks, volumes, environment variables, and more.
Basic Example of a docker-compose.yml:
yaml
Copy code
version: "3.8"
services:
  web:
    build: .
    ports:
      - "8000:8000"
  db:
    image: postgres
    environment:
      POSTGRES_PASSWORD: example
What it does:
Defines two services: web and db.
Builds a custom image for the web service (e.g., from the Dockerfile).
Uses the official postgres image for the db service.
Links the services together so they can communicate.
Key Differences
Feature	Dockerfile	docker-compose.yml
Purpose	Defines how to build a single Docker image.	Defines how to run and manage multi-container Docker applications.
Scope	Focuses on building a single image.	Focuses on managing the configuration of multiple containers.
File Format	Shell-like script, with commands like RUN, COPY, CMD.	YAML configuration format for services, networks, volumes, etc.
Use Case	Used when you need to build a custom image.	Used when you want to orchestrate multiple services (like web and database) working together.
Image Creation	Builds a Docker image from the instructions.	Uses prebuilt images or builds from a Dockerfile.
Service Management	Cannot manage multiple containers directly.	Defines how services interact, their networks, and volumes.
Dependencies	No concept of dependencies between containers.	Can define dependencies between services (e.g., depends_on).
Networks and Volumes	Cannot define networks or volumes.	Can define custom networks and volumes for services.
Example Usage	Building a Python app or Node.js server image.	Running a web app with Nginx, MySQL, and Redis in separate containers.
How They Work Together
In many cases, docker-compose.yml and Dockerfile are used together:

Dockerfile is used to build a custom image with your application and its dependencies.
docker-compose.yml is used to define and manage multiple services (containers) and how they interact (e.g., a web app, database, caching service, etc.).
Workflow Example:
Create a Dockerfile: Define how to build your application container.
Create a docker-compose.yml: Use this file to start your custom container (from the Dockerfile) along with other services like databases, caches, etc.
Run docker-compose up: Compose will start the multiple containers, build images if needed, and manage the whole application.
When to Use What:
Use Dockerfile when you need to create a custom Docker image for your application (e.g., a web app with dependencies).
Use docker-compose.yml when you need to manage multiple services, connect containers, define networks, and orchestrate how containers work together.
In essence, Dockerfile is for building images, and docker-compose.yml is for running and managing containers in a multi-service environment.

---

# wordpress
### dockerfile

Let’s break down your Dockerfile for WordPress and address its correctness and functionality. Here's a more detailed explanation of each part:

1. Base Image Selection:
dockerfile
Copy code
# Use Debian as a base image (Debian 12)
FROM debian:bookworm
What it does:
This line sets the base image for your container to Debian 12 (Bookworm). Since your requirement was to use the penultimate stable version of Debian, this is correct for now (as the latest would be "Debian 13").
Why it matters:
Using Debian ensures you have a stable, general-purpose Linux distribution with access to extensive software packages. It also allows for optimizations specific to Debian’s package management system (apt).
2. Updating the Package Manager and Installing Dependencies:
dockerfile
Copy code
# Update & install your package manager
RUN apt-get -y update && \
	apt-get install php-fpm php-mysql -y && \
	apt-get install curl -y
What it does:

apt-get -y update updates the package manager's local cache of available packages.
apt-get install php-fpm php-mysql -y installs php-fpm (FastCGI Process Manager) and php-mysql (PHP extension for MySQL). These are essential for running WordPress: php-fpm handles PHP processes, and php-mysql allows PHP to communicate with MySQL/MariaDB databases.
apt-get install curl -y installs curl, a tool used to transfer data from or to a server. It’s useful for downloading WordPress during setup or handling other external requests.
Why it matters:

The php-fpm and php-mysql packages are critical for serving PHP files and connecting to the MariaDB database in your setup. Without these, the WordPress container cannot function properly.
3. Copying the Custom WordPress Setup Script:
dockerfile
Copy code
COPY ./tools/wp-script.sh /
What it does:

This copies the script wp-script.sh from the tools directory on your local machine into the container’s root directory (/).
The script likely contains custom steps to set up WordPress, such as downloading WordPress files, setting correct permissions, or initializing the environment.
Why it matters:

Scripts like this can automate the setup of WordPress, handling tasks that otherwise would have to be done manually. It provides a repeatable way to configure the container correctly.
Ensure that this script is executable by setting the right permissions with chmod +x.
4. Exposing Port 9000:
dockerfile
Copy code
# Make port 9000 available to the world outside this container
EXPOSE 9000
What it does:

This line tells Docker to expose port 9000 of the container, which is the port on which php-fpm will listen. This is the port that NGINX will use to communicate with WordPress (via PHP-FPM).
Why it matters:

Exposing this port is necessary for other services (like NGINX in this case) to connect to this container. Without exposing it, no other container or external service could interact with the PHP-FPM process running inside this container.
5. Defining the Command to Run:
dockerfile
Copy code
# Define the command to run the app
CMD ["/.wp-script.sh"]
What it does:

This defines the default command that runs when the container starts. In this case, it is set to run your wp-script.sh script, which presumably sets up and configures WordPress.
However, there is a mistake here: the path /./wp-script.sh is incorrect; it should be /wp-script.sh (since the script was copied to the root directory).
Why it matters:

The CMD directive is essential for ensuring that the container performs its intended function when it starts. If this script is not correctly defined, the container will fail to start or work improperly.
In your case, the correct path would be /wp-script.sh because the script was copied to the root directory (/).
Suggested Corrections:
Fix the path for the startup script:

The path in CMD should be /wp-script.sh, not /.wp-script.sh.
Ensure PHP-FPM is started correctly:

php-fpm should be started to handle PHP requests. You can add a line in the script to start php-fpm or directly start it in the CMD.
You could modify the CMD directive to start php-fpm and also execute the WordPress setup script.
Here’s a revised version of the Dockerfile:

dockerfile
Copy code
# Use Debian as a base image (Debian 12)
FROM debian:bookworm

# Update & install necessary packages
RUN apt-get -y update && \
    apt-get install -y php-fpm php-mysql curl && \
    apt-get clean && rm -rf /var/lib/apt/lists/*

# Copy the WordPress setup script
COPY ./tools/wp-script.sh /

# Make sure the script is executable
RUN chmod +x /wp-script.sh

# Expose port 9000 for PHP-FPM
EXPOSE 9000

# Start PHP-FPM and run the custom WordPress script
CMD ["/bin/bash", "/wp-script.sh"]
Explanation of Changes:
Added chmod +x: Ensures that the wp-script.sh file is executable inside the container.
Fixed the CMD path: Changed CMD to /wp-script.sh and used bash to execute it properly.
Included php-fpm handling: Ensure that php-fpm is running in your wp-script.sh file or separately configure php-fpm to run in the CMD section.
Make sure your wp-script.sh does everything necessary to prepare WordPress, including downloading the WordPress files if they are not in the image already, configuring wp-config.php, and starting php-fpm. Here's an example of what it might include:

bash
Copy code
#!/bin/bash

# Download and unpack WordPress if not already installed
if [ ! -f /var/www/html/wp-config.php ]; then
  curl -O https://wordpress.org/latest.tar.gz
  tar -xzf latest.tar.gz -C /var/www/html --strip-components=1
  rm latest.tar.gz
fi

# Start PHP-FPM service
php-fpm7.4 -F
This script checks if WordPress is already installed (based on the presence of wp-config.php), downloads it if necessary, and then starts PHP-FPM to handle incoming requests.

6. Defining the Default Command:
dockerfile
Copy code
CMD ["/bin/bash", "/wp-script.sh"]
This sets the default command to be executed when the container starts. You are running the wp-script.sh script using /bin/bash.

Important Considerations:

Make sure that your wp-script.sh does two critical things:
Install and Configure WordPress: Download WordPress, configure database credentials (through wp-config.php), and ensure that WordPress files are in the right place.
Start PHP-FPM: It should start the php-fpm process to handle incoming PHP requests. If php-fpm isn't started, the container will not be able to serve any requests.
Example of wp-script.sh:
bash
Copy code
#!/bin/bash

# Download and unpack WordPress if not already present
if [ ! -f /var/www/html/wp-config.php ]; then
  echo "Downloading WordPress..."
  curl -O https://wordpress.org/latest.tar.gz
  tar -xzf latest.tar.gz -C /var/www/html --strip-components=1
  rm latest.tar.gz
  echo "WordPress downloaded and extracted."
fi

# Move the custom wp-config.php into place
mv /wp-config.php /var/www/html/wp-config.php

# Start PHP-FPM in the foreground
echo "Starting PHP-FPM..."
php-fpm7.4 -F
Explanation of the Script:
Download and Extract WordPress:

It checks if wp-config.php already exists in the /var/www/html directory (where WordPress files should reside). If it doesn't, the script downloads and extracts WordPress.
Move wp-config.php:

This moves your custom wp-config.php to the correct location inside the WordPress directory (/var/www/html).
Start PHP-FPM:

The php-fpm7.4 -F command starts the php-fpm service and keeps it running in the foreground (-F). This is essential for the container to keep running and handle PHP requests.


could i also do this?
CMD ["/wp-script.sh"]

instead of this 
CMD ["/bin/bash", "/wp-script.sh"]?

ChatGPT said:
ChatGPT
Yes, you can use the following:

dockerfile
Copy code
CMD ["/wp-script.sh"]
Key Differences and Considerations:
Direct Execution vs. Using Bash:

CMD ["/wp-script.sh"]: This attempts to run the wp-script.sh directly. For this to work, the script needs to have a proper "shebang" (#!/bin/bash or #!/bin/sh) at the top. The shebang tells the system which interpreter (like bash or sh) to use when running the script. If the shebang is missing, the system may not know how to execute the script.

Example of a proper shebang at the start of the script:

bash
Copy code
#!/bin/bash
CMD ["/bin/bash", "/wp-script.sh"]: This explicitly runs the script with bash. Even if the shebang is missing or if the script isn’t marked executable, this ensures the script is run by bash.

When to use each:

Use CMD ["/wp-script.sh"] if:
Your script has a proper shebang (#!/bin/bash or #!/bin/sh) at the top.
The script is marked executable (chmod +x /wp-script.sh).
Use CMD ["/bin/bash", "/wp-script.sh"] if:
You want to ensure the script runs with bash no matter what.
You don’t need the script to be executable (though it's still a good practice to make it executable).

### wp-config.php
```php
<?php
/**
 * The base configuration for WordPress
 *
 * The wp-config.php creation script uses this file during the
 * installation. You don't have to use the web site, you can
 * copy this file to "wp-config.php" and fill in the values.
 *
 * This file contains the following configurations:
 *
 * * MySQL settings
 * * Secret keys
 * * Database table prefix
 * * ABSPATH
 *
 * @link https://wordpress.org/support/article/editing-wp-config-php/
 *
 * @package WordPress
 */

// ** MySQL settings - You can get this info from your web host ** //
/** The name of the database for WordPress */
define( 'DB_NAME', 'db1' );

/** MySQL database username */
define( 'DB_USER', 'user' );

/** MySQL database password */
define( 'DB_PASSWORD', 'pwd' );

/** MySQL hostname */
define( 'DB_HOST', 'mariadb' );

/** Database Charset to use in creating database tables. */
define( 'DB_CHARSET', 'utf8' );

/** The Database Collate type. Don't change this if in doubt. */
define( 'DB_COLLATE', '' );

define( 'WP_ALLOW_REPAIR', true );

/**#@+
 * Authentication Unique Keys and Salts.
 *
 * Change these to different unique phrases!
 * You can generate these using the {@link https://api.wordpress.org/secret-key/1.1/salt/ WordPress.org secret-key service}
 * You can change these at any point in time to invalidate all existing cookies. This will force all users to have to log in again.
 *
 * @since 2.6.0
 */
define( 'AUTH_KEY',         '):Uw9 :|7$m3yy=c^IM%d8}zG6yXY%25SDUyr.r#GcDP)[b25Yn$sDLNwR~I=kwq' );
define( 'SECURE_AUTH_KEY',  'lBWxAzhu=StQ(s-[t_D8yH8_`0NiM~d[m q<{Hri]n#UM3J;@x[ne;,k<~cN`~%,' );
define( 'LOGGED_IN_KEY',    ' /e+%ecWs`>hA<s`|+7rmujt>3MA}GD*n=D7W%$8h*Xc!jP?hn+fw0#;;g{Ywl@k' );
define( 'NONCE_KEY',        ' -cX{xQc|GjD$=kXd,|lUX5)*oT)ru3^px-iU{q;`1If22EqIwA0/lPIIbpbtB=C' );
define( 'AUTH_SALT',        'U9LX s1@q6$[*VV,MUhL7tS@;I9t_u*uDQIfZdG.ei1Amy$*.RI_TSTz#y=X.>Wq' );
define( 'SECURE_AUTH_SALT', '0<MR&l4v=cZ)8Ke/#ip>2<Ed@ j<#pvLaOMc-jEFM9^tr`X*T2qDIB@)gg.0<e2V' );
define( 'LOGGED_IN_SALT',   'xSHh4B]r[~)h%n$f(dCt;mD}#q gy$<{ >qGgPS>XH*]jH>W<!10>H<_16l{(OdP' );
define( 'NONCE_SALT',       '7Ea$kvU|lkO8&X]b7^#K+w! lH2)SOelLiaYYX(Zz)Ebk_]-#m,J&aM<*JedFa| ' );

define( 'WP_REDIS_HOST', 'redis' );
define( 'WP_REDIS_PORT', 6379 );     


define('WP_CACHE', true);

/**#@-*/

/**
 * WordPress Database Table prefix.
 *
 * You can have multiple installations in one database if you give each
 * a unique prefix. Only numbers, letters, and underscores please!
 */
$table_prefix = 'wp_';

/**
 * For developers: WordPress debugging mode.
 *
 * Change this to true to enable the display of notices during development.
 * It is strongly recommended that plugin and theme developers use WP_DEBUG
 * in their development environments.
 *
 * For information on other constants that can be used for debugging,
 * visit the documentation.
 *
 * @link https://wordpress.org/support/article/debugging-in-wordpress/
 */
define( 'WP_DEBUG', true );

/* That's all, stop editing! Happy publishing. */

/** Absolute path to the WordPress directory. */
if ( ! defined( 'ABSPATH' ) ) {
	define( 'ABSPATH', __DIR__ . '/' );
}

/** Sets up WordPress vars and included files. */
require_once ABSPATH . 'wp-settings.php';
?>
```

---


# mariadb
### dockerfile



---


Connect your terminal to the VM:
FIRST:
VM Settings -> Network -> Advanced -> Port Forwarding -> Click on the 'plus' right side
Host IP: 127.0.0.1
Host Port: 2222 -> could be any port number
Guest Port: 22 -> default SSH port on the guest

SECOND:
In VM terminal:
```
$> sudo apt install openssh-server
```
Password:
```
$> sudo systemctl start ssh
```

THIRD:
```ssh -p 2222 jmetzger@127.0.0.1``` 
-> ssh -p <port> <username>@127.0.0.1
password:
Test:
```
$> ls
$> cd desktop
$> touch IamHERE
```
-> file should appear on your VM desktop

```
$> exit
```
-> if you want to exit the syncrontaion

FOUR:
Syncronize VS and VM:
Steps to Connect VS Code to Your VM via SSH:
Ensure SSH Access to Your VM: Make sure you've set up SSH access to your VM by following the steps mentioned earlier (setting up port forwarding in VirtualBox and ensuring SSH is running on your VM). You should be able to SSH into the VM from your terminal.

Test the SSH connection using your terminal:

bash
Copy code
ssh -p 2222 <username>@127.0.0.1
Install VS Code (if not already installed): Download and install Visual Studio Code on your main system.

Install the Remote - SSH Extension:

Open VS Code.
Go to the Extensions view by clicking the Extensions icon on the sidebar or pressing Ctrl+Shift+X.
In the search bar, type "Remote - SSH".
Click Install on the "Remote - SSH" extension by Microsoft.
Open the Command Palette:

Open the Command Palette in VS Code by pressing Ctrl+Shift+P (or Cmd+Shift+P on macOS).
In the Command Palette, type Remote-SSH: Connect to Host and select it.
Configure Your SSH Host:

If this is your first time using SSH in VS Code, it will prompt you to configure an SSH host.

Enter the SSH connection string for your VM, similar to this:

bash
Copy code
ssh -p 2222 <username>@127.0.0.1
Example:

bash
Copy code
ssh -p 2222 ubuntu@127.0.0.1
Edit SSH Configuration (optional):

If you want to add the SSH host to your config file for easier access, VS Code will ask if you want to do that. Choose "Add to SSH config" if prompted.

Alternatively, you can manually add an entry in your ~/.ssh/config file (if it doesn't exist, you can create it):

bash
Copy code
Host my-vm
    HostName 127.0.0.1
    Port 2222
    User ubuntu
Now you can connect to your VM by just typing my-vm as the host name in VS Code.

Connect to the SSH Host:

Once you've entered the SSH details, VS Code will attempt to connect to the remote machine.
It will open a new window, and you may be asked to install the VS Code Server on the remote machine (the VM). Accept the installation if prompted.
Work on Your Remote Files: Once connected, you can open folders and files on the remote VM directly from VS Code. You can also install extensions on the remote VM and use VS Code as if you were working locally, but everything will happen on the VM.

---

- Go to VM Settings -> Shared Folders
- Click the + icon to add a new shared folder
- Folder Path: The path to the shared folder on you host (Create before this step a folder on your host)
- Folder Name: Name of the folder you created on the host (Fill in should happen automatically)
- Mount Point: /mnt/shared
- Set Auto-mount option
- OK
- Start your VM
- sudo ./VBoxLinuxAdditions.run
- 'cd..' till you find the mnt folder
sudo mount -t vboxsf <foldername> /mnt/shared
Replace <foldername> with the name you set for the shared folder.
- 'cd' into /mnt/shared (You will find all yo
